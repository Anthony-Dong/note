# 负载均衡
### 1.概念
	负载均衡(Load Balance)是高可用网络基础架构的的一个关键组成部分，有了负载均衡，我们通常可以将我们的应用服务器部署多台，然后通过负载均衡将用户的请求分发到不同的服务器用来提高网站、应用、数据库或其他服务的性能以及可靠性。
## 2.引入负载均衡器的原因:	
### 2.1著名的单点故障问题

![image](https://tyut.oss-cn-beijing.aliyuncs.com/image/2019-09-14/09c27a79-553e-4a06-b755-a9057b8a934c.png?x-oss-process=style/template01)

	单点故障（英语：single point of failure，缩写SPOF）是指系统中一点失效，就会让整个系统无法运作的部件，换句话说，单点故障即会整体故障。
	
	上图中的架构有什么缺陷了？首先，用户是通过网络直接和web服务器相连，想象一下，如果这个服务器挂了（这种情况随时都可能发生的)，那么用户的请求就会得不到响应，将无法访问该网站，这就是著名的单点故障问题，这肯定是不行的，一般而言，商业上的网站其可靠性需要达到至少4个9，也就是99.99&以上。
	
	其次，即使服务器是正常工作的情况，但是如果很多用户在同一时间内访问服务器，超过了服务器的处理能力，那么会出现响应速度慢甚至无法连接的情况，这也是用户无法接受的。
	
	负载均衡的出现可以很好的解决上面两个问题，通过引入一个负载均衡器和至少两个web 服务器，可以有效的解决上面两个问题。注：通常情况下，所有的后端服务器会保证提供相同的内容，以便用户无论哪个服务器响应，都能收到一致的内容。
### 2.1引入单个负载均衡器
![image](https://tyut.oss-cn-beijing.aliyuncs.com/image/2019-09-14/40c0b439-a620-4ef4-a994-b23ce7dedf5a.png?x-oss-process=style/template01)
	
	上图架构，现在，即使App 01即使挂了，负载均衡会将用户的请求转发到正常工作的App 02上，这解决了上面的第一个问题；其次，根据业务需要，负载均衡后端的App可以很方便的扩展，这样就能解决第上面的第二个问题。但是，现在单点故障问题转移到了负载均衡器，可以通过引入第二个负载均衡器来缓解，后面还会讲到。
## 负载均衡器的实现原理
### 1.负载均衡如何选择要转发的后端服务器

	负载均衡器一般根据两个因素来决定要将请求转发到哪个服务器。
	1：确保所选择的后端服务器是正常工作的，能给对用户的请求做出响应；
	2：根据预先设置的负载均衡算法从健康服务器池中进行选择。
	由于负载均衡器只应当选择能正常做出响应的后端服务器，因此就需要有一种机制能判断它所连的后端服务器是否正常工作。为了监视后台服务器的运行状况，运行状态检查服务会定期尝试使用转发规则定义的协议和端口去连接后端服务器。如果某个服务器没有通过健康检查，就会从健康池中剔除，保证流量不会被转发到该服务器，直到其再次通过健康检查为止。

### 2.负载均衡算法
![imager](https://tyut.oss-cn-beijing.aliyuncs.com/image/2019-09-14/06e2f4e2-0e8a-4397-a442-6875b483e280.png?x-oss-process=style/template01)


	负载均衡算法决定了后端的哪些健康服务器会被选中。下面是几个常用的算法，这里只是简单介绍，不具体研究其算法实现了，后面会专门用一篇文章来总结：
	
	1.轮询：为第一个请求选择健康池中的第一个后端服务器，然后按顺序往后依次选择，直到最后一个，然后循环。将请求按顺序轮流地分配到后端服务器上，它均衡地对待后端的每一台服务器，而不关心服务器实际的连接数和当前的系统负载。
	
	2.随机法:通过系统的随机算法，根据后端服务器的列表大小值来随机选取其中的一台服务器进行访问。由概率统计理论可以得知，随着客户端调用服务端的次数增多，其实际效果越来越接近于平均分配调用量到后端的每一台服务器，也就是轮询的结果。
	
	3.源地址哈希的思想是根据获取客户端的IP地址，通过哈希函数计算得到的一个数值，用该数值对服务器列表的大小进行取模运算，得到的结果便是客服端要访问服务器的序号。采用源地址哈希法进行负载均衡，同一IP地址的客户端，当后端服务器列表不变时，它每次都会映射到同一台后端服务器进行访问。
	
	4.加权轮询法:不同的后端服务器可能机器的配置和当前系统的负载并不相同，因此它们的抗压能力也不相同。给配置高、负载低的机器配置更高的权重，让其处理更多的请；而配置低、负载高的机器，给其分配较低的权重，降低其系统负载，加权轮询能很好地处理这一问题，并将请求顺序且按照权重分配到后端。
	
	5、加权随机法:与加权轮询法一样，加权随机法也根据后端机器的配置，系统的负载分配不同的权重。不同的是，它是按照权重随机请求后端服务器，而非顺序。
	
	6、最小连接数法:最小连接数算法比较灵活和智能，由于后端服务器的配置不尽相同，对于请求的处理有快有慢，它是根据后端服务器当前的连接情况，动态地选取其中当前积压连接数最少的一台服务器来处理当前的请求，尽可能地提高后端服务的利用效率，将负责合理地分流到每一台服务器。

### 3.解决负载均衡器单点问题
	可以将第二个负载均衡器连接到第一个上，从而形成一个集群
![imager](https://tyut.oss-cn-beijing.aliyuncs.com/image/2019-09-14/35bcc698-e5c8-41f1-83e7-919daee2ac13.png?x-oss-process=style/template01)
	
### 4. nginx负载均衡算法
![image](https://tyut.oss-cn-beijing.aliyuncs.com/image/2019-09-14/6cea583b-f189-4ec6-90cd-70131a5cfd9c.png?x-oss-process=style/template01)
	
	1.轮询（默认）每个请求按时间顺序逐一分配到不同的后端服务器，如果后端服务器down掉，能自动剔除。
	2.weight 指定轮询几率，weight和访问比率成正比，用于后端服务器性能不均的情况。
	http{
		upstream bakend {  
		  server 192.168.0.14 weight=10;  
		  server 192.168.0.15 weight=10;  
		}
		server{}
	}
	
	3.ip_hash
	upstream bakend {  
	  ip_hash;  
	  server 192.168.0.14:88;  
	  server 192.168.0.15:80;  
	}
	4.fair 按后端服务器的响应时间来分配请求，响应时间短的优先分配。
	upstream backend {  
	  server server1;  
	  server server2;  
	  fair;  
	}
	5. url_hash 按访问url的hash结果来分配请求，使每个url定向到同一个后端服务器，后端服务器为缓存时比较有效。
	upstream backend {  
	  server squid1:3128;  
	  server squid2:3128;  
	  hash $request_uri;  
	  hash_method crc32;  
	}
	
	6.例子
	
	upstream bakend{#定义负载均衡设备的Ip及设备状态  
	  ip_hash;  
	  server 127.0.0.1:9090 down;  
	  server 127.0.0.1:8080 weight=2;  
	  server 127.0.0.1:6060;  
	  server 127.0.0.1:7070 backup;  
	} 
	每个设备的状态设置为：
	1.down 表示单前的server暂时不参与负载
	2.weight 默认为1.weight越大，负载的权重就越大。
	3.maxfails ：允许请求失败的次数默认为1.当超过最大次数时，返回proxynextupstream 模块定义的错误
	4.failtimeout:max_fails次失败后，暂停的时间。
	5.backup： 其它所有的非backup机器down或者忙的时候，请求backup机器。所以这台机器压力会最轻。

